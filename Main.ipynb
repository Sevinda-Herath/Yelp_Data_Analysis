{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f884e9b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup (Linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f86a01",
   "metadata": {},
   "source": [
    "### 1.1. Update Linux Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe5bec",
   "metadata": {},
   "source": [
    "### 1.2. Install Python and Packages (pip & venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52576065",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install -y python3 python3-pip python3-venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc654e",
   "metadata": {},
   "source": [
    "### 1.3. Create a Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93b893",
   "metadata": {},
   "source": [
    "### 1.4. Activate the Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90569cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844bedf",
   "metadata": {},
   "source": [
    "### 1.5. Install the Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17105a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ed447",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49886907",
   "metadata": {},
   "source": [
    "### 2.1. Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a847186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user-agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\" \\\n",
    "\"https://business.yelp.com/external-assets/files/Yelp-JSON.zip\" \\\n",
    "-O Yelp-JSON.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec941fdd",
   "metadata": {},
   "source": [
    "### 2.2. Unzip the downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecee569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded file\n",
    "!unzip -o Yelp-JSON.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets directory\n",
    "!mkdir Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the extracted tar file to Datasets directory\n",
    "!tar -xvf Yelp\\ JSON/yelp_dataset.tar -C Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary files\n",
    "!rm Yelp-JSON.zip\n",
    "!rm -rf __MACOSX/\n",
    "!rm -rf Yelp\\ JSON/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e66524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt update\n",
    "# sudo apt install -y openjdk-17-jdk\n",
    "\n",
    "# # Verify Java 17 is present\n",
    "# ls -d /usr/lib/jvm/java-17-openjdk-amd64 || echo \"Java 17 not found\"\n",
    "\n",
    "# # Force your shell to prefer Java 17 and unset JAVA_TOOL_OPTIONS\n",
    "# echo 'export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> ~/.bashrc\n",
    "# echo 'export PATH=$JAVA_HOME/bin:$PATH' >> ~/.bashrc\n",
    "# echo 'unset JAVA_TOOL_OPTIONS' >> ~/.bashrc\n",
    "# source ~/.bashrc\n",
    "\n",
    "# # Confirm\n",
    "# which java\n",
    "# java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b208435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/12 20:14:24 WARN Utils: Your hostname, codespaces-4d50f8 resolves to a loopback address: 127.0.0.1; using 10.0.0.15 instead (on interface eth0)\n",
      "25/12/12 20:14:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/12 20:14:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize Spark\n",
    "import os\n",
    "\n",
    "# Pin Java 17 for Spark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"root\"\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Yelp Data - Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.hadoop.security.authentication\", \"simple\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7655c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/12 20:16:26 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business_df = spark.read.json(\"Datasets/yelp_academic_dataset_business.json\")\n",
    "checkin_df = spark.read.json(\"Datasets/yelp_academic_dataset_checkin.json\")\n",
    "review_df = spark.read.json(\"Datasets/yelp_academic_dataset_review.json\")\n",
    "tip_df = spark.read.json(\"Datasets/yelp_academic_dataset_tip.json\")\n",
    "user_df = spark.read.json(\"Datasets/yelp_academic_dataset_user.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b85268",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "This section applies consistent, reproducible cleaning steps for each dataset using Spark DataFrames. Goals:\n",
    "- Remove exact duplicate rows\n",
    "- Handle missing values with sensible defaults\n",
    "- Normalize data types (dates, booleans, nested structs)\n",
    "- Trim whitespace and standardize text where relevant\n",
    "- Validate schemas and basic constraints\n",
    "- Cache cleaned DataFrames for downstream use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c50dc",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8b0f3",
   "metadata": {},
   "source": [
    "## 5. Data Querying"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
